{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import requests\n",
    "import time\n",
    "from pandarallel import pandarallel\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandarallel.initialize(progress_bar=True, nb_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(keyword: str,titles: str) -> str:\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    tries = 0\n",
    "    description = \"\"\n",
    "    \n",
    "    while tries < 5:  \n",
    "        try:\n",
    "            tries += 1\n",
    "            response= openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"},\n",
    "                {\"role\": \"user\", \"content\": \"\"},\n",
    "                {\"role\": \"assistant\", \"content\": \"\"},\n",
    "                {\"role\": \"user\", \"content\": f\"\"}\n",
    "            ],\n",
    "            temperature=0.3,\n",
    "            max_tokens=800\n",
    "            )\n",
    "            description = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            return description\n",
    "        \n",
    "        except Exception as e:\n",
    "            time.sleep(2**tries)\n",
    "\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
